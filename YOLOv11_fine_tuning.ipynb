{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzkfAb7pAJxp"
      },
      "source": [
        "# Fine-Tuning YOLOv11 With Our Dataset\n",
        "\n",
        "#### Course: Deep Neural Engineering (IM1102)\n",
        "#### Group: Ellen Cordemans, Ilse Harmers & Sem Pepels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs4iJn8DCyBB"
      },
      "source": [
        "The code in this notebook is adapted from [1].\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**References**\n",
        "\n",
        "[1] Kondrackis, L. (2024, December 5). How to Train YOLOv11 Instance\n",
        "Segmentation on a Custom Dataset. Roboflow Blog. Retrieved April 15, 2025, from https://blog.roboflow.com/train-yolov11-instance-segmentation/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUhxiIku7ZXv"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuxXEXScV3cr"
      },
      "outputs": [],
      "source": [
        "# Checking the availability of Google Colab's GPU.\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HxKtLAQvWZmC"
      },
      "outputs": [],
      "source": [
        "# Installing Roboflow and Ultralytics libraries.\n",
        "!pip -q install \"roboflow==1.1.58\" \"ultralytics==8.3.95\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_IU5lm8VXBg"
      },
      "outputs": [],
      "source": [
        "# Importing important models, functions and libraries.\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import re\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import locale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq5YpsC47GRk"
      },
      "source": [
        "## Fine-Tune a YOLOv11 Segmentation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYg1Nk9pXDUo"
      },
      "outputs": [],
      "source": [
        "# Downloading our dataset from Roboflow.\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "project = rf.workspace(\"workspace-v0o55\").project(\"parsing-house-facades\")\n",
        "version = project.version(10)   # Train-Val-Test: 70-15-15.\n",
        "dataset = version.download(\"yolov11\")\n",
        "dataset_path = f\"{dataset.location}/data.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzroy-VcXJxs"
      },
      "outputs": [],
      "source": [
        "# Checking whether cuda is available for Torch to use as device.\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Cuda is available. Torch will use Cuda.\")\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    print(\"MPS is available. Torch will use MPS.\")\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    print(\"GPU is not available. Torch will fall back to CPU.\")\n",
        "    device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmGV1Gv5Dmaj"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbN8-5wLkmsw"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"Pretrained_models/yolo11l-seg.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrMARrwQcUvl"
      },
      "outputs": [],
      "source": [
        "# We wanted to perform a hyperparameter search, but the free resources provided by Google Colab\n",
        "# are not enough to run this process within a reasonable time (i.e., < ~ 4 hours). Even when reducing\n",
        "# the amount of parameters in the search, the runtime remains too lengthy for Colab's (free) GPU to handle.\n",
        "search_space = {\n",
        "    \"lr0\": (1e-5, 1e-1),\n",
        "    \"momentum\": (0.6, 0.98),\n",
        "    \"weight_decay\": (0.0, 0.001),\n",
        "    \"box\": (0.02, 0.2),\n",
        "    \"cls\": (0.2, 4.0),\n",
        "}\n",
        "\n",
        "model.tune(\n",
        "    data=dataset_path,\n",
        "    epochs=30,\n",
        "    iterations=100,\n",
        "    space=search_space,\n",
        "    plots=False,\n",
        "    save=False,\n",
        "    val=False,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKhBXDKefU75"
      },
      "source": [
        "### Fine-Tuning a YOLOv11 Segmentation Model Based On Our Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHRcFmx5XPrS"
      },
      "outputs": [],
      "source": [
        "# For fine-tuning YOLOv11, we have chosen the second-to-last largest version as explained in the report.\n",
        "# Note that running this cell takes a long while (~ 30 minutes).\n",
        "results = model.train(data=dataset_path, epochs=100, imgsz=640, degrees=0.0, flipud=0.0, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch0xTc1rN6u_"
      },
      "outputs": [],
      "source": [
        "# Saving the train results to a ZIP file.\n",
        "# This line might become deprecated when training multiple runs in one session, since the new directory will be saved as 'train{+1}'.\n",
        "!zip -r /content/runs/segment/train/train.zip /content/runs/segment/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELnNw4yfgkZZ"
      },
      "source": [
        "### Testing Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9D_hNgKkG50"
      },
      "outputs": [],
      "source": [
        "# Determining metrics on the test set.\n",
        "metrics = model.val(data=dataset_path, split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSNvqNdxJseX"
      },
      "outputs": [],
      "source": [
        "# Saving the test results to a ZIP file.\n",
        "# This line might become deprecated when training multiple runs in one session, since the new directory will be saved as 'train{+1}'.\n",
        "!zip -r /content/runs/segment/train2/test.zip /content/runs/segment/train2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZsmzhv_rqux"
      },
      "outputs": [],
      "source": [
        "# In this cell, we display the quantitative results on the test set.\n",
        "# Printing class labels.\n",
        "print(f\"Labels: {metrics.names}\")\n",
        "\n",
        "# Box AP metrics.\n",
        "AP50b = metrics.box.ap50\n",
        "AP50_95b = metrics.box.ap\n",
        "# Segmentation AP metrics.\n",
        "AP50s = metrics.seg.ap50\n",
        "AP50_95s = metrics.seg.ap\n",
        "\n",
        "print(f\"AP@50: {AP50b} (B) & {AP50s} (S)\")\n",
        "print(f\"AP@50-95: {AP50_95b} (B) & {AP50_95s} (S)\\n\")\n",
        "\n",
        "# Box mAP metrics.\n",
        "mAP50b = metrics.box.map50\n",
        "mAP50_95b = metrics.box.map\n",
        "# Segmentation mAP metrics.\n",
        "mAP50s = metrics.seg.map50\n",
        "mAP50_95s = metrics.seg.map\n",
        "\n",
        "print(f\"mAP@50: {mAP50b} (B) & {mAP50s} (S)\")\n",
        "print(f\"mAP@50-95: {mAP50_95b} (B) & {mAP50_95s} (S)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWua85FL8ETA"
      },
      "outputs": [],
      "source": [
        "# Displaying the confusion matrix of the test set for IoU = 0.45 (default value in Ultralytics library).\n",
        "folder_segment_content = os.listdir(\"/content/runs/segment\")\n",
        "test_folder = None\n",
        "\n",
        "# Extracting the most recently saved 'train' directory in which the test results were stored.\n",
        "def extract_last_number(s):\n",
        "    match = re.search(r'train(\\d+)', s)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    elif s == \"train\":\n",
        "        return -float('inf')\n",
        "    return float('inf')\n",
        "\n",
        "if len(folder_segment_content) == 1:\n",
        "  test_folder == folder_segment_content[0]\n",
        "else:\n",
        "  filtered_list = [s for s in folder_segment_content if re.search(r'train\\d*', s)]\n",
        "  sorted_list = sorted(filtered_list, key=extract_last_number, reverse=True)\n",
        "  test_folder = sorted_list[0]\n",
        "\n",
        "# Displaying the (normalized) confusion matrix of the test data.\n",
        "img = Image.open(f\"/content/runs/segment/{test_folder}/confusion_matrix_normalized.png\")\n",
        "img_resized = img.resize((img.width // 4, img.height // 4))\n",
        "display(img_resized)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
